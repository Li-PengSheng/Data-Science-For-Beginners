<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "116c5d361fbe812e59a73f37ce721d36",
  "translation_date": "2025-08-26T21:01:27+00:00",
  "source_file": "2-Working-With-Data/07-python/README.md",
  "language_code": "th"
}
-->
# การทำงานกับข้อมูล: Python และ Pandas Library

| ![ Sketchnote โดย [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/07-WorkWithPython.png) |
| :-------------------------------------------------------------------------------------------------------: |
|                 การทำงานกับ Python - _Sketchnote โดย [@nitya](https://twitter.com/nitya)_                 |

[![วิดีโอแนะนำ](../../../../translated_images/video-ds-python.245247dc811db8e4d5ac420246de8a118c63fd28f6a56578d08b630ae549f260.th.png)](https://youtu.be/dZjWOGbsN4Y)

แม้ว่าฐานข้อมูลจะเป็นวิธีที่มีประสิทธิภาพในการจัดเก็บข้อมูลและเรียกใช้ข้อมูลด้วยภาษาคำสั่ง แต่การเขียนโปรแกรมเพื่อจัดการข้อมูลด้วยตัวเองถือเป็นวิธีที่ยืดหยุ่นที่สุด ในหลายกรณี การใช้คำสั่งฐานข้อมูลอาจมีประสิทธิภาพมากกว่า แต่ในบางกรณีที่ต้องการการประมวลผลข้อมูลที่ซับซ้อนมากขึ้น SQL อาจไม่สามารถทำได้ง่าย ๆ 

การประมวลผลข้อมูลสามารถเขียนโปรแกรมได้ในทุกภาษา แต่มีบางภาษาที่เหมาะสมกับการทำงานกับข้อมูลมากกว่า นักวิทยาศาสตร์ข้อมูลมักนิยมใช้ภาษาต่อไปนี้:

* **[Python](https://www.python.org/)** เป็นภาษาการเขียนโปรแกรมทั่วไปที่มักถูกมองว่าเป็นตัวเลือกที่ดีที่สุดสำหรับผู้เริ่มต้นเนื่องจากความเรียบง่าย Python มีไลบรารีเพิ่มเติมมากมายที่ช่วยแก้ปัญหาต่าง ๆ เช่น การดึงข้อมูลจากไฟล์ ZIP หรือการแปลงภาพเป็นสีเทา นอกจากการวิเคราะห์ข้อมูล Python ยังถูกใช้ในงานพัฒนาเว็บไซต์บ่อยครั้ง
* **[R](https://www.r-project.org/)** เป็นเครื่องมือดั้งเดิมที่พัฒนาขึ้นเพื่อการประมวลผลข้อมูลเชิงสถิติ R มีคลังไลบรารีขนาดใหญ่ (CRAN) ทำให้เป็นตัวเลือกที่ดีสำหรับการประมวลผลข้อมูล อย่างไรก็ตาม R ไม่ใช่ภาษาการเขียนโปรแกรมทั่วไป และไม่ค่อยถูกใช้ในงานนอกเหนือจากการวิเคราะห์ข้อมูล
* **[Julia](https://julialang.org/)** เป็นอีกหนึ่งภาษาที่พัฒนาขึ้นเพื่อการวิเคราะห์ข้อมูลโดยเฉพาะ โดยมีเป้าหมายเพื่อให้ประสิทธิภาพดีกว่า Python ทำให้เป็นเครื่องมือที่ยอดเยี่ยมสำหรับการทดลองทางวิทยาศาสตร์

ในบทเรียนนี้ เราจะมุ่งเน้นการใช้ Python ในการประมวลผลข้อมูลแบบง่าย ๆ โดยสมมติว่าคุณมีความคุ้นเคยพื้นฐานกับภาษา Python หากคุณต้องการเรียนรู้ Python อย่างลึกซึ้ง สามารถดูแหล่งข้อมูลต่อไปนี้:

* [เรียนรู้ Python อย่างสนุกสนานด้วย Turtle Graphics และ Fractals](https://github.com/shwars/pycourse) - คอร์สแนะนำ Python บน GitHub
* [เริ่มต้นเรียนรู้ Python](https://docs.microsoft.com/en-us/learn/paths/python-first-steps/?WT.mc_id=academic-77958-bethanycheum) เส้นทางการเรียนรู้บน [Microsoft Learn](http://learn.microsoft.com/?WT.mc_id=academic-77958-bethanycheum)

ข้อมูลสามารถมาในหลายรูปแบบ ในบทเรียนนี้ เราจะพิจารณาข้อมูลในสามรูปแบบ - **ข้อมูลแบบตาราง**, **ข้อความ** และ **ภาพ**

เราจะมุ่งเน้นตัวอย่างการประมวลผลข้อมูลบางส่วนแทนที่จะให้ภาพรวมทั้งหมดของไลบรารีที่เกี่ยวข้อง วิธีนี้จะช่วยให้คุณเข้าใจแนวคิดหลักของสิ่งที่เป็นไปได้ และรู้ว่าจะหาวิธีแก้ปัญหาได้จากที่ไหนเมื่อคุณต้องการ

> **คำแนะนำที่มีประโยชน์ที่สุด** เมื่อคุณต้องการทำงานบางอย่างกับข้อมูลที่คุณไม่รู้วิธีทำ ลองค้นหาวิธีในอินเทอร์เน็ต [Stackoverflow](https://stackoverflow.com/) มักมีตัวอย่างโค้ด Python ที่มีประโยชน์สำหรับงานทั่วไปมากมาย

## [แบบทดสอบก่อนเรียน](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/12)

## ข้อมูลแบบตารางและ Dataframes

คุณเคยพบข้อมูลแบบตารางเมื่อเราพูดถึงฐานข้อมูลเชิงสัมพันธ์ เมื่อคุณมีข้อมูลจำนวนมากและข้อมูลนั้นถูกจัดเก็บในหลายตารางที่เชื่อมโยงกัน การใช้ SQL ในการทำงานกับข้อมูลนั้นถือเป็นทางเลือกที่เหมาะสม อย่างไรก็ตาม มีหลายกรณีที่เรามีตารางข้อมูลและต้องการเข้าใจหรือวิเคราะห์ข้อมูล เช่น การกระจายตัว ความสัมพันธ์ระหว่างค่า เป็นต้น ในการวิเคราะห์ข้อมูล มีหลายกรณีที่เราต้องทำการแปลงข้อมูลต้นฉบับและตามด้วยการสร้างภาพ ทั้งสองขั้นตอนนี้สามารถทำได้ง่าย ๆ ด้วย Python

มีไลบรารีที่มีประโยชน์ที่สุดสองตัวใน Python ที่ช่วยคุณจัดการกับข้อมูลแบบตาราง:
* **[Pandas](https://pandas.pydata.org/)** ช่วยให้คุณจัดการกับ **Dataframes** ซึ่งคล้ายกับตารางในฐานข้อมูลเชิงสัมพันธ์ คุณสามารถมีคอลัมน์ที่มีชื่อ และทำการดำเนินการต่าง ๆ กับแถว คอลัมน์ และ Dataframes โดยรวม
* **[Numpy](https://numpy.org/)** เป็นไลบรารีสำหรับการทำงานกับ **tensors** หรือ **arrays** หลายมิติ Array มีค่าที่มีประเภทเดียวกัน และง่ายกว่า Dataframe แต่มีการดำเนินการทางคณิตศาสตร์มากกว่า และสร้าง overhead น้อยกว่า

นอกจากนี้ยังมีไลบรารีอื่น ๆ ที่คุณควรรู้จัก:
* **[Matplotlib](https://matplotlib.org/)** เป็นไลบรารีที่ใช้สำหรับการสร้างภาพข้อมูลและการวาดกราฟ
* **[SciPy](https://www.scipy.org/)** เป็นไลบรารีที่มีฟังก์ชันทางวิทยาศาสตร์เพิ่มเติม เราเคยพูดถึงไลบรารีนี้เมื่อพูดถึงความน่าจะเป็นและสถิติ

นี่คือตัวอย่างโค้ดที่คุณมักใช้ในการนำเข้าไลบรารีเหล่านี้ในตอนต้นของโปรแกรม Python:
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import ... # you need to specify exact sub-packages that you need
``` 

Pandas มีแนวคิดพื้นฐานอยู่ไม่กี่อย่าง

### Series 

**Series** คือชุดของค่าที่คล้ายกับ list หรือ numpy array ความแตกต่างหลักคือ series มี **index** และเมื่อเราดำเนินการกับ series (เช่น การบวก) index จะถูกนำมาพิจารณาด้วย Index อาจเป็นตัวเลขแถวแบบง่าย ๆ (เป็น index ที่ใช้โดยค่าเริ่มต้นเมื่อสร้าง series จาก list หรือ array) หรืออาจมีโครงสร้างที่ซับซ้อน เช่น ช่วงเวลา

> **หมายเหตุ**: มีโค้ด Pandas เบื้องต้นใน notebook ที่แนบมาชื่อ [`notebook.ipynb`](notebook.ipynb) เราเพียงแค่สรุปตัวอย่างบางส่วนที่นี่ และคุณสามารถตรวจสอบ notebook ฉบับเต็มได้

ลองพิจารณาตัวอย่าง: เราต้องการวิเคราะห์ยอดขายของร้านไอศกรีมของเรา ลองสร้าง series ของตัวเลขยอดขาย (จำนวนสินค้าที่ขายได้ในแต่ละวัน) สำหรับช่วงเวลาหนึ่ง:

```python
start_date = "Jan 1, 2020"
end_date = "Mar 31, 2020"
idx = pd.date_range(start_date,end_date)
print(f"Length of index is {len(idx)}")
items_sold = pd.Series(np.random.randint(25,50,size=len(idx)),index=idx)
items_sold.plot()
```
![กราฟ Time Series](../../../../translated_images/timeseries-1.80de678ab1cf727e50e00bcf24009fa2b0a8b90ebc43e34b99a345227d28e467.th.png)

สมมติว่าในแต่ละสัปดาห์เราจัดปาร์ตี้สำหรับเพื่อน ๆ และนำไอศกรีมเพิ่มอีก 10 แพ็คสำหรับปาร์ตี้ เราสามารถสร้าง series อีกตัวที่มี index เป็นสัปดาห์เพื่อแสดงสิ่งนี้:
```python
additional_items = pd.Series(10,index=pd.date_range(start_date,end_date,freq="W"))
```
เมื่อเราบวก series สองตัวเข้าด้วยกัน เราจะได้ยอดรวม:
```python
total_items = items_sold.add(additional_items,fill_value=0)
total_items.plot()
```
![กราฟ Time Series](../../../../translated_images/timeseries-2.aae51d575c55181ceda81ade8c546a2fc2024f9136934386d57b8a189d7570ff.th.png)

> **หมายเหตุ** เราไม่ได้ใช้ไวยากรณ์ง่าย ๆ `total_items+additional_items` หากเราใช้ เราจะได้รับค่ามากมายที่เป็น `NaN` (*Not a Number*) ใน series ที่ได้ นี่เป็นเพราะมีค่าที่หายไปสำหรับบาง index ใน series `additional_items` และการบวก `NaN` กับอะไรก็ตามจะได้ผลลัพธ์เป็น `NaN` ดังนั้นเราจำเป็นต้องระบุพารามิเตอร์ `fill_value` ระหว่างการบวก

สำหรับ time series เราสามารถ **resample** series ด้วยช่วงเวลาที่แตกต่างกันได้ ตัวอย่างเช่น สมมติว่าเราต้องการคำนวณยอดขายเฉลี่ยรายเดือน เราสามารถใช้โค้ดต่อไปนี้:
```python
monthly = total_items.resample("1M").mean()
ax = monthly.plot(kind='bar')
```
![กราฟ Time Series เฉลี่ยรายเดือน](../../../../translated_images/timeseries-3.f3147cbc8c624881008564bc0b5d9fcc15e7374d339da91766bd0e1c6bd9e3af.th.png)

### DataFrame

DataFrame คือชุดของ series ที่มี index เดียวกัน เราสามารถรวม series หลายตัวเข้าด้วยกันเป็น DataFrame:
```python
a = pd.Series(range(1,10))
b = pd.Series(["I","like","to","play","games","and","will","not","change"],index=range(0,9))
df = pd.DataFrame([a,b])
```
สิ่งนี้จะสร้างตารางแนวนอนดังนี้:
|     | 0   | 1    | 2   | 3   | 4      | 5   | 6      | 7    | 8    |
| --- | --- | ---- | --- | --- | ------ | --- | ------ | ---- | ---- |
| 0   | 1   | 2    | 3   | 4   | 5      | 6   | 7      | 8    | 9    |
| 1   | I   | like | to  | use | Python | and | Pandas | very | much |

เรายังสามารถใช้ Series เป็นคอลัมน์ และระบุชื่อคอลัมน์โดยใช้ dictionary:
```python
df = pd.DataFrame({ 'A' : a, 'B' : b })
```
สิ่งนี้จะให้ตารางดังนี้:

|     | A   | B      |
| --- | --- | ------ |
| 0   | 1   | I      |
| 1   | 2   | like   |
| 2   | 3   | to     |
| 3   | 4   | use    |
| 4   | 5   | Python |
| 5   | 6   | and    |
| 6   | 7   | Pandas |
| 7   | 8   | very   |
| 8   | 9   | much   |

**หมายเหตุ** เราสามารถได้รูปแบบตารางนี้โดยการ transpose ตารางก่อนหน้า เช่น โดยการเขียน 
```python
df = pd.DataFrame([a,b]).T..rename(columns={ 0 : 'A', 1 : 'B' })
```
ที่นี่ `.T` หมายถึงการดำเนินการ transpose DataFrame คือการสลับแถวและคอลัมน์ และการดำเนินการ `rename` ช่วยให้เราสามารถเปลี่ยนชื่อคอลัมน์ให้ตรงกับตัวอย่างก่อนหน้า

นี่คือการดำเนินการที่สำคัญที่สุดบางส่วนที่เราสามารถทำได้กับ DataFrames:

**การเลือกคอลัมน์** เราสามารถเลือกคอลัมน์แต่ละคอลัมน์โดยการเขียน `df['A']` - การดำเนินการนี้จะคืนค่า Series เราสามารถเลือกชุดย่อยของคอลัมน์เป็นอีก DataFrame โดยการเขียน `df[['B','A']]` - สิ่งนี้จะคืนค่า DataFrame อีกตัว

**การกรอง** เฉพาะแถวที่ตรงตามเกณฑ์ ตัวอย่างเช่น เพื่อให้เหลือเฉพาะแถวที่มีคอลัมน์ `A` มากกว่า 5 เราสามารถเขียน `df[df['A']>5]`

> **หมายเหตุ** วิธีการกรองทำงานดังนี้ การแสดงออก `df['A']<5` จะคืนค่า boolean series ซึ่งระบุว่าแสดงออกเป็น `True` หรือ `False` สำหรับแต่ละองค์ประกอบของ series ดั้งเดิม `df['A']` เมื่อ boolean series ถูกใช้เป็น index จะคืนค่าชุดย่อยของแถวใน DataFrame ดังนั้นจึงไม่สามารถใช้การแสดงออก boolean ของ Python ได้ เช่น การเขียน `df[df['A']>5 and df['A']<7]` จะผิด แทนที่จะใช้การดำเนินการพิเศษ `&` บน boolean series โดยการเขียน `df[(df['A']>5) & (df['A']<7)]` (*วงเล็บมีความสำคัญที่นี่*)

**การสร้างคอลัมน์ใหม่ที่คำนวณได้** เราสามารถสร้างคอลัมน์ใหม่ที่คำนวณได้สำหรับ DataFrame ของเราได้อย่างง่ายดายโดยใช้การแสดงออกที่เข้าใจง่าย เช่นนี้:
```python
df['DivA'] = df['A']-df['A'].mean() 
``` 
ตัวอย่างนี้คำนวณ divergence ของ A จากค่าเฉลี่ยของมัน สิ่งที่เกิดขึ้นจริงคือเรากำลังคำนวณ series และจากนั้นกำหนด series นี้ให้กับด้านซ้ายมือ สร้างคอลัมน์ใหม่ ดังนั้น เราไม่สามารถใช้การดำเนินการใด ๆ ที่ไม่เข้ากันกับ series ตัวอย่างเช่น โค้ดด้านล่างผิด:
```python
# Wrong code -> df['ADescr'] = "Low" if df['A'] < 5 else "Hi"
df['LenB'] = len(df['B']) # <- Wrong result
``` 
ตัวอย่างหลัง แม้ว่าจะถูกต้องตามไวยากรณ์ แต่ให้ผลลัพธ์ที่ผิด เพราะมันกำหนดความยาวของ series `B` ให้กับค่าทั้งหมดในคอลัมน์ และไม่ใช่ความยาวขององค์ประกอบแต่ละตัวตามที่เราตั้งใจไว้

หากเราต้องการคำนวณการแสดงออกที่ซับซ้อนเช่นนี้ เราสามารถใช้ฟังก์ชัน `apply` ตัวอย่างสุดท้ายสามารถเขียนได้ดังนี้:
```python
df['LenB'] = df['B'].apply(lambda x : len(x))
# or 
df['LenB'] = df['B'].apply(len)
```

หลังจากการดำเนินการข้างต้น เราจะได้ DataFrame ดังนี้:

|     | A   | B      | DivA | LenB |
| --- | --- | ------ | ---- | ---- |
| 0   | 1   | I      | -4.0 | 1    |
| 1   | 2   | like   | -3.0 | 4    |
| 2   | 3   | to     | -2.0 | 2    |
| 3   | 4   | use    | -1.0 | 3    |
| 4   | 5   | Python | 0.0  | 6    |
| 5   | 6   | and    | 1.0  | 3    |
| 6   | 7   | Pandas | 2.0  | 6    |
| 7   | 8   | very   | 3.0  | 4    |
| 8   | 9   | much   | 4.0  | 4    |

**การเลือกแถวตามตัวเลข** สามารถทำได้โดยใช้โครงสร้าง `iloc` ตัวอย่างเช่น เพื่อเลือก 5 แถวแรกจาก DataFrame:
```python
df.iloc[:5]
```

**การจัดกลุ่ม** มักถูกใช้เพื่อให้ได้ผลลัพธ์ที่คล้ายกับ *pivot tables* ใน Excel สมมติว่าเราต้องการคำนวณค่าเฉลี่ยของคอลัมน์ `A` สำหรับแต่ละจำนวนของ `LenB` เราสามารถจัดกลุ่ม DataFrame ของเราด้วย `LenB` และเรียกใช้ `mean`:
```python
df.groupby(by='LenB').mean()
```
หากเราต้องการคำนวณค่าเฉลี่ยและจำนวนองค์ประกอบในกลุ่ม เราสามารถใช้ฟังก์ชัน `aggregate` ที่ซับซ้อนกว่า:
```python
df.groupby(by='LenB') \
 .aggregate({ 'DivA' : len, 'A' : lambda x: x.mean() }) \
 .rename(columns={ 'DivA' : 'Count', 'A' : 'Mean'})
```
สิ่งนี้จะให้ตารางดังนี้:

| LenB | Count | Mean     |
| ---- | ----- | -------- |
| 1    | 1     | 1.000000 |
| 2    | 1     | 3.000000 |
| 3    | 2     | 5.000000 |
| 4    | 3     | 6.333333 |
| 6    | 2     | 6.000000 |

### การดึงข้อมูล
เราได้เห็นแล้วว่าการสร้าง Series และ DataFrames จากวัตถุใน Python นั้นง่ายมาก อย่างไรก็ตาม ข้อมูลมักจะมาในรูปแบบไฟล์ข้อความ หรือ ตาราง Excel โชคดีที่ Pandas มีวิธีง่ายๆ ในการโหลดข้อมูลจากดิสก์ ตัวอย่างเช่น การอ่านไฟล์ CSV สามารถทำได้ง่ายๆ ดังนี้:
```python
df = pd.read_csv('file.csv')
```
เราจะเห็นตัวอย่างเพิ่มเติมเกี่ยวกับการโหลดข้อมูล รวมถึงการดึงข้อมูลจากเว็บไซต์ภายนอกในส่วน "Challenge"

### การพิมพ์และการสร้างกราฟ

นักวิทยาศาสตร์ข้อมูลมักต้องสำรวจข้อมูล ดังนั้นการสามารถมองเห็นข้อมูลได้จึงเป็นสิ่งสำคัญ เมื่อ DataFrame มีขนาดใหญ่ หลายครั้งเราต้องการเพียงตรวจสอบว่าเราทำทุกอย่างถูกต้องโดยการพิมพ์แถวแรกๆ ออกมา ซึ่งสามารถทำได้โดยการเรียกใช้ `df.head()` หากคุณใช้งานจาก Jupyter Notebook มันจะพิมพ์ DataFrame ออกมาในรูปแบบตารางที่ดูดี

เรายังได้เห็นการใช้ฟังก์ชัน `plot` เพื่อสร้างกราฟสำหรับบางคอลัมน์ แม้ว่า `plot` จะมีประโยชน์สำหรับหลายงาน และรองรับกราฟหลากหลายประเภทผ่านพารามิเตอร์ `kind=` คุณยังสามารถใช้ไลบรารี `matplotlib` เพื่อสร้างกราฟที่ซับซ้อนมากขึ้น เราจะครอบคลุมการสร้างภาพข้อมูลในรายละเอียดในบทเรียนของหลักสูตรแยกต่างหาก

ภาพรวมนี้ครอบคลุมแนวคิดที่สำคัญที่สุดของ Pandas อย่างไรก็ตาม ไลบรารีนี้มีความหลากหลายมาก และไม่มีข้อจำกัดในสิ่งที่คุณสามารถทำได้! ตอนนี้เรามาใช้ความรู้นี้ในการแก้ปัญหาเฉพาะกัน

## 🚀 Challenge 1: การวิเคราะห์การแพร่กระจายของ COVID

ปัญหาแรกที่เราจะมุ่งเน้นคือการสร้างแบบจำลองการแพร่ระบาดของ COVID-19 เพื่อทำสิ่งนี้ เราจะใช้ข้อมูลเกี่ยวกับจำนวนผู้ติดเชื้อในประเทศต่างๆ ซึ่งจัดทำโดย [Center for Systems Science and Engineering](https://systems.jhu.edu/) (CSSE) ที่ [Johns Hopkins University](https://jhu.edu/) ชุดข้อมูลนี้สามารถเข้าถึงได้ใน [GitHub Repository นี้](https://github.com/CSSEGISandData/COVID-19)

เนื่องจากเราต้องการแสดงวิธีการจัดการกับข้อมูล เราขอเชิญคุณเปิด [`notebook-covidspread.ipynb`](notebook-covidspread.ipynb) และอ่านตั้งแต่ต้นจนจบ คุณยังสามารถรันเซลล์ และทำแบบท้าทายที่เราได้ทิ้งไว้ให้คุณในตอนท้าย

![COVID Spread](../../../../translated_images/covidspread.f3d131c4f1d260ab0344d79bac0abe7924598dd754859b165955772e1bd5e8a2.th.png)

> หากคุณไม่ทราบวิธีการรันโค้ดใน Jupyter Notebook ลองดู [บทความนี้](https://soshnikov.com/education/how-to-execute-notebooks-from-github/)

## การทำงานกับข้อมูลที่ไม่มีโครงสร้าง

แม้ว่าข้อมูลมักจะมาในรูปแบบตาราง ในบางกรณีเราจำเป็นต้องจัดการกับข้อมูลที่มีโครงสร้างน้อยกว่า เช่น ข้อความหรือภาพ ในกรณีนี้ เพื่อใช้เทคนิคการประมวลผลข้อมูลที่เราได้เห็นข้างต้น เราจำเป็นต้อง **ดึง** ข้อมูลที่มีโครงสร้างออกมา ตัวอย่างเช่น:

* การดึงคำสำคัญจากข้อความ และดูว่าคำสำคัญเหล่านั้นปรากฏบ่อยแค่ไหน
* การใช้เครือข่ายประสาทเทียมเพื่อดึงข้อมูลเกี่ยวกับวัตถุในภาพ
* การรับข้อมูลเกี่ยวกับอารมณ์ของผู้คนจากฟีดกล้องวิดีโอ

## 🚀 Challenge 2: การวิเคราะห์เอกสาร COVID

ในความท้าทายนี้ เราจะดำเนินการต่อในหัวข้อการระบาดของ COVID และมุ่งเน้นไปที่การประมวลผลเอกสารวิชาการเกี่ยวกับเรื่องนี้ มี [CORD-19 Dataset](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) ที่มีเอกสารมากกว่า 7000 ฉบับ (ในขณะที่เขียน) เกี่ยวกับ COVID ซึ่งมีข้อมูลเมตาและบทคัดย่อ (และสำหรับประมาณครึ่งหนึ่งของเอกสารมีข้อความเต็มให้ด้วย)

ตัวอย่างเต็มของการวิเคราะห์ชุดข้อมูลนี้โดยใช้ [Text Analytics for Health](https://docs.microsoft.com/azure/cognitive-services/text-analytics/how-tos/text-analytics-for-health/?WT.mc_id=academic-77958-bethanycheum) บริการวิเคราะห์ข้อความเชิงสุขภาพสามารถดูได้ [ในบล็อกโพสต์นี้](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/) เราจะพูดถึงเวอร์ชันที่เรียบง่ายของการวิเคราะห์นี้

> **NOTE**: เราไม่ได้ให้สำเนาของชุดข้อมูลเป็นส่วนหนึ่งของ repository นี้ คุณอาจต้องดาวน์โหลดไฟล์ [`metadata.csv`](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge?select=metadata.csv) จาก [ชุดข้อมูลนี้บน Kaggle](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) การลงทะเบียนกับ Kaggle อาจจำเป็น คุณยังสามารถดาวน์โหลดชุดข้อมูลโดยไม่ต้องลงทะเบียน [จากที่นี่](https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html) แต่จะรวมข้อความเต็มทั้งหมดนอกเหนือจากไฟล์ข้อมูลเมตา

เปิด [`notebook-papers.ipynb`](notebook-papers.ipynb) และอ่านตั้งแต่ต้นจนจบ คุณยังสามารถรันเซลล์ และทำแบบท้าทายที่เราได้ทิ้งไว้ให้คุณในตอนท้าย

![Covid Medical Treatment](../../../../translated_images/covidtreat.b2ba59f57ca45fbcda36e0ddca3f8cfdddeeed6ca879ea7f866d93fa6ec65791.th.png)

## การประมวลผลข้อมูลภาพ

เมื่อเร็วๆ นี้ โมเดล AI ที่ทรงพลังมากได้ถูกพัฒนาขึ้น ซึ่งช่วยให้เราเข้าใจภาพได้ มีหลายงานที่สามารถแก้ไขได้โดยใช้เครือข่ายประสาทเทียมที่ผ่านการฝึกฝนมาแล้ว หรือบริการคลาวด์ ตัวอย่างบางส่วนได้แก่:

* **Image Classification** ซึ่งช่วยให้คุณจัดหมวดหมู่ภาพเป็นหนึ่งในคลาสที่กำหนดไว้ล่วงหน้า คุณสามารถฝึกตัวจัดหมวดหมู่ภาพของคุณเองได้อย่างง่ายดายโดยใช้บริการ เช่น [Custom Vision](https://azure.microsoft.com/services/cognitive-services/custom-vision-service/?WT.mc_id=academic-77958-bethanycheum)
* **Object Detection** เพื่อตรวจจับวัตถุต่างๆ ในภาพ บริการ เช่น [computer vision](https://azure.microsoft.com/services/cognitive-services/computer-vision/?WT.mc_id=academic-77958-bethanycheum) สามารถตรวจจับวัตถุทั่วไปจำนวนมาก และคุณสามารถฝึกโมเดล [Custom Vision](https://azure.microsoft.com/services/cognitive-services/custom-vision-service/?WT.mc_id=academic-77958-bethanycheum) เพื่อตรวจจับวัตถุเฉพาะที่คุณสนใจ
* **Face Detection** รวมถึงการตรวจจับอายุ เพศ และอารมณ์ สิ่งนี้สามารถทำได้ผ่าน [Face API](https://azure.microsoft.com/services/cognitive-services/face/?WT.mc_id=academic-77958-bethanycheum)

บริการคลาวด์ทั้งหมดนี้สามารถเรียกใช้ได้โดยใช้ [Python SDKs](https://docs.microsoft.com/samples/azure-samples/cognitive-services-python-sdk-samples/cognitive-services-python-sdk-samples/?WT.mc_id=academic-77958-bethanycheum) และสามารถรวมเข้ากับเวิร์กโฟลว์การสำรวจข้อมูลของคุณได้อย่างง่ายดาย

ตัวอย่างบางส่วนของการสำรวจข้อมูลจากแหล่งข้อมูลภาพ:
* ในบล็อกโพสต์ [How to Learn Data Science without Coding](https://soshnikov.com/azure/how-to-learn-data-science-without-coding/) เราสำรวจภาพถ่าย Instagram โดยพยายามทำความเข้าใจว่าอะไรทำให้ผู้คนกดไลค์ภาพถ่ายมากขึ้น เราเริ่มต้นด้วยการดึงข้อมูลจากภาพถ่ายให้ได้มากที่สุดโดยใช้ [computer vision](https://azure.microsoft.com/services/cognitive-services/computer-vision/?WT.mc_id=academic-77958-bethanycheum) และจากนั้นใช้ [Azure Machine Learning AutoML](https://docs.microsoft.com/azure/machine-learning/concept-automated-ml/?WT.mc_id=academic-77958-bethanycheum) เพื่อสร้างโมเดลที่เข้าใจได้
* ใน [Facial Studies Workshop](https://github.com/CloudAdvocacy/FaceStudies) เราใช้ [Face API](https://azure.microsoft.com/services/cognitive-services/face/?WT.mc_id=academic-77958-bethanycheum) เพื่อดึงอารมณ์ของผู้คนในภาพถ่ายจากเหตุการณ์ต่างๆ เพื่อพยายามทำความเข้าใจว่าอะไรทำให้ผู้คนมีความสุข

## สรุป

ไม่ว่าคุณจะมีข้อมูลที่มีโครงสร้างหรือไม่มีโครงสร้างอยู่แล้ว การใช้ Python คุณสามารถดำเนินการทุกขั้นตอนที่เกี่ยวข้องกับการประมวลผลและการทำความเข้าใจข้อมูลได้ มันอาจเป็นวิธีที่ยืดหยุ่นที่สุดในการประมวลผลข้อมูล และนี่คือเหตุผลที่นักวิทยาศาสตร์ข้อมูลส่วนใหญ่ใช้ Python เป็นเครื่องมือหลัก การเรียนรู้ Python อย่างลึกซึ้งอาจเป็นความคิดที่ดีหากคุณจริงจังกับการเดินทางในสายงานวิทยาศาสตร์ข้อมูลของคุณ!

## [แบบทดสอบหลังการบรรยาย](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/13)

## ทบทวนและศึกษาด้วยตนเอง

**หนังสือ**
* [Wes McKinney. Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](https://www.amazon.com/gp/product/1491957662)

**แหล่งข้อมูลออนไลน์**
* บทเรียนอย่างเป็นทางการ [10 minutes to Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)
* [เอกสารเกี่ยวกับการสร้างภาพข้อมูลใน Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html)

**การเรียนรู้ Python**
* [เรียนรู้ Python อย่างสนุกสนานด้วย Turtle Graphics และ Fractals](https://github.com/shwars/pycourse)
* [เริ่มต้นเรียนรู้ Python](https://docs.microsoft.com/learn/paths/python-first-steps/?WT.mc_id=academic-77958-bethanycheum) Learning Path บน [Microsoft Learn](http://learn.microsoft.com/?WT.mc_id=academic-77958-bethanycheum)

## งานที่ได้รับมอบหมาย

[ทำการศึกษาข้อมูลเพิ่มเติมสำหรับความท้าทายข้างต้น](assignment.md)

## เครดิต

บทเรียนนี้ถูกเขียนขึ้นด้วย ♥️ โดย [Dmitry Soshnikov](http://soshnikov.com)

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามอย่างเต็มที่เพื่อให้การแปลมีความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่แม่นยำ เอกสารต้นฉบับในภาษาต้นทางควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่มีความสำคัญ แนะนำให้ใช้บริการแปลภาษาจากผู้เชี่ยวชาญ เราจะไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความที่ผิดพลาดซึ่งเกิดจากการใช้การแปลนี้