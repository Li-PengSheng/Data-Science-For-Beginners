<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8796f41f566a0a8ebb72863a83d558ed",
  "translation_date": "2025-08-26T15:04:07+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "hu"
}
-->
# Bevezet√©s az adatetika vil√°g√°ba

|![ Sketchnote k√©sz√≠tette: [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Adattudom√°nyi etika - _Sketchnote k√©sz√≠tette: [@nitya](https://twitter.com/nitya)_ |

---

Mindannyian adatpolg√°rok vagyunk egy adatokkal √°tsz≈ëtt vil√°gban.

A piaci trendek azt mutatj√°k, hogy 2022-re minden harmadik nagy szervezet online [piactereken √©s t≈ëzsd√©ken](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/) kereszt√ºl fog adatokat v√°s√°rolni √©s eladni. **Alkalmaz√°sfejleszt≈ëk√©nt** egyre k√∂nnyebb √©s olcs√≥bb lesz adatvez√©relt betekint√©seket √©s algoritmusvez√©relt automatiz√°ci√≥t integr√°lni a mindennapi felhaszn√°l√≥i √©lm√©nyekbe. Azonban, ahogy a mesters√©ges intelligencia (MI) mindent √°that√≥v√° v√°lik, meg kell √©rten√ºnk azokat a potenci√°lis k√°rokat is, amelyeket az ilyen algoritmusok [fegyverk√©nt val√≥ alkalmaz√°sa](https://www.youtube.com/watch?v=TQHs8SA1qpk) okozhat nagy l√©pt√©kben.

A trendek azt is jelzik, hogy 2025-re t√∂bb mint [180 zettab√°jtnyi](https://www.statista.com/statistics/871513/worldwide-data-created/) adatot fogunk l√©trehozni √©s fogyasztani. **Adattud√≥sk√©nt** ez p√©ld√°tlan szint≈± hozz√°f√©r√©st biztos√≠t sz√°munkra a szem√©lyes adatokhoz. Ez lehet≈ëv√© teszi, hogy felhaszn√°l√≥i viselked√©si profilokat √©p√≠ts√ºnk, √©s olyan d√∂nt√©shozatalt befoly√°soljunk, amely [a szabad v√°laszt√°s ill√∫zi√≥j√°t](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) kelti, mik√∂zben esetleg a sz√°munkra kedvez≈ë eredm√©nyek fel√© terelj√ºk a felhaszn√°l√≥kat. Ez sz√©lesebb k√∂r≈± k√©rd√©seket is felvet az adatv√©delemr≈ël √©s a felhaszn√°l√≥i jogok v√©delm√©r≈ël.

Az adatetika ma m√°r _elengedhetetlen ir√°nyelv_ az adattudom√°ny √©s a m√©rn√∂ki munka sz√°m√°ra, amely seg√≠t minimaliz√°lni az adatvez√©relt cselekedeteinkb≈ël ered≈ë potenci√°lis k√°rokat √©s nem sz√°nd√©kos k√∂vetkezm√©nyeket. A [Gartner MI Hype Cycle](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) azonos√≠tja a digit√°lis etika, a felel≈ës MI √©s az MI ir√°ny√≠t√°s relev√°ns trendjeit, mint kulcsfontoss√°g√∫ hajt√≥er≈ëket az MI _demokratiz√°l√°sa_ √©s _iparos√≠t√°sa_ k√∂r√ºli nagyobb megatrendekhez.

![Gartner MI Hype Cycle - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

Ebben a leck√©ben az adatetika leny≈±g√∂z≈ë ter√ºlet√©t fogjuk felfedezni - az alapfogalmakt√≥l √©s kih√≠v√°sokt√≥l kezdve az esettanulm√°nyokon √°t az alkalmazott MI fogalmakig, mint p√©ld√°ul az ir√°ny√≠t√°s -, amelyek seg√≠tenek az etikai kult√∫ra kialak√≠t√°s√°ban az adatokkal √©s MI-vel dolgoz√≥ csapatokban √©s szervezetekben.

## [El≈ëad√°s el≈ëtti kv√≠z](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/2) üéØ

## Alapvet≈ë meghat√°roz√°sok

Kezdj√ºk az alapvet≈ë terminol√≥gia meg√©rt√©s√©vel.

Az "etika" sz√≥ a [g√∂r√∂g "ethikos"](https://en.wikipedia.org/wiki/Ethics) (√©s annak gy√∂kere, az "ethos") sz√≥b√≥l sz√°rmazik, amely _jellemet vagy erk√∂lcsi term√©szetet_ jelent.

**Etika** azokr√≥l a k√∂z√∂s √©rt√©kekr≈ël √©s erk√∂lcsi elvekr≈ël sz√≥l, amelyek ir√°ny√≠tj√°k viselked√©s√ºnket a t√°rsadalomban. Az etika nem t√∂rv√©nyeken alapul, hanem azon a sz√©les k√∂rben elfogadott norm√°n, hogy mi a "helyes √©s helytelen". Azonban az etikai megfontol√°sok befoly√°solhatj√°k a v√°llalatir√°ny√≠t√°si kezdem√©nyez√©seket √©s a korm√°nyzati szab√°lyoz√°sokat, amelyek t√∂bb √∂szt√∂nz≈ët teremtenek a megfelel√©sre.

**Adatetika** egy [√∫j etikai √°g](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1), amely "az _adatokkal, algoritmusokkal √©s a hozz√°juk kapcsol√≥d√≥ gyakorlatokkal_ kapcsolatos erk√∂lcsi probl√©m√°kat tanulm√°nyozza √©s √©rt√©keli". Itt az **"adatok"** az adatok gener√°l√°s√°val, r√∂gz√≠t√©s√©vel, kur√°l√°s√°val, feldolgoz√°s√°val, terjeszt√©s√©vel, megoszt√°s√°val √©s felhaszn√°l√°s√°val kapcsolatos cselekv√©sekre √∂sszpontos√≠tanak, az **"algoritmusok"** az MI-re, √ºgyn√∂k√∂kre, g√©pi tanul√°sra √©s robotokra, m√≠g a **"gyakorlatok"** olyan t√©m√°kra, mint a felel≈ës innov√°ci√≥, programoz√°s, hackel√©s √©s etikai k√≥dexek.

**Alkalmazott etika** az [erk√∂lcsi megfontol√°sok gyakorlati alkalmaz√°sa](https://en.wikipedia.org/wiki/Applied_ethics). Ez az a folyamat, amely sor√°n akt√≠van vizsg√°ljuk az etikai k√©rd√©seket a _val√≥s cselekv√©sek, term√©kek √©s folyamatok_ kontextus√°ban, √©s korrekci√≥s int√©zked√©seket tesz√ºnk annak √©rdek√©ben, hogy ezek √∂sszhangban maradjanak a meghat√°rozott etikai √©rt√©keinkkel.

**Etikai kult√∫ra** az [_alkalmazott etika operacionaliz√°l√°s√°r√≥l_](https://hbr.org/2019/05/how-to-design-an-ethical-organization) sz√≥l, hogy biztos√≠tsuk, hogy etikai elveinket √©s gyakorlatainkat k√∂vetkezetesen √©s sk√°l√°zhat√≥ m√≥don alkalmazz√°k a szervezet eg√©sz√©ben. A sikeres etikai kult√∫r√°k szervezet-szint≈± etikai elveket hat√°roznak meg, jelent≈ës √∂szt√∂nz≈ëket biztos√≠tanak a megfelel√©shez, √©s meger≈ës√≠tik az etikai norm√°kat az√°ltal, hogy minden szinten √∂szt√∂nzik √©s er≈ës√≠tik a k√≠v√°nt viselked√©seket.

## Etikai fogalmak

Ebben a r√©szben olyan fogalmakat t√°rgyalunk, mint a **k√∂z√∂s √©rt√©kek** (elvek) √©s az **etikai kih√≠v√°sok** (probl√©m√°k) az adatetika ter√ºlet√©n - valamint **esettanulm√°nyokat** vizsg√°lunk, amelyek seg√≠tenek meg√©rteni ezeket a fogalmakat a val√≥s kontextusokban.

### 1. Etikai elvek

Minden adatetikai strat√©gia az _etikai elvek_ meghat√°roz√°s√°val kezd≈ëdik - azokkal a "k√∂z√∂s √©rt√©kekkel", amelyek le√≠rj√°k az elfogadhat√≥ viselked√©seket, √©s ir√°ny√≠tj√°k a megfelel≈ës√©gi cselekv√©seket az adat- √©s MI-projektjeinkben. Ezeket egy√©ni vagy csapatszinten is meghat√°rozhatjuk. Azonban a legt√∂bb nagy szervezet ezeket egy _etikus MI_ k√ºldet√©snyilatkozatban vagy keretrendszerben foglalja √∂ssze, amelyet v√°llalati szinten hat√°roznak meg, √©s k√∂vetkezetesen √©rv√©nyes√≠tenek minden csapatban.

**P√©lda:** A Microsoft [Felel≈ës MI](https://www.microsoft.com/en-us/ai/responsible-ai) k√ºldet√©snyilatkozata √≠gy sz√≥l: _"Elk√∂telezettek vagyunk az MI fejl≈ëd√©se ir√°nt, amelyet olyan etikai elvek vez√©relnek, amelyek az embereket helyezik el≈ët√©rbe"_ - az al√°bbi keretrendszerben 6 etikai elvet azonos√≠tva:

![Felel≈ës MI a Microsoftn√°l](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Vizsg√°ljuk meg r√∂viden ezeket az elveket. A _transzparencia_ √©s az _elsz√°moltathat√≥s√°g_ alapvet≈ë √©rt√©kek, amelyekre a t√∂bbi elv √©p√ºl - kezdj√ºk ezekkel:

* [**Elsz√°moltathat√≥s√°g**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) biztos√≠tja, hogy a szakemberek _felel≈ëss√©get v√°llaljanak_ adat- √©s MI-m≈±veleteik√©rt, valamint az etikai elvek betart√°s√°√©rt.
* [**Transzparencia**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) biztos√≠tja, hogy az adat- √©s MI-m≈±veletek _√©rthet≈ëek_ legyenek a felhaszn√°l√≥k sz√°m√°ra, megmagyar√°zva a d√∂nt√©sek m√∂g√∂tti mit √©s mi√©rt.
* [**M√©lt√°nyoss√°g**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - biztos√≠tja, hogy az MI _minden embert_ m√©lt√°nyosan kezeljen, kezelve az adat- √©s rendszerszint≈± implicit t√°rsadalmi-technikai torz√≠t√°sokat.
* [**Megb√≠zhat√≥s√°g √©s biztons√°g**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - biztos√≠tja, hogy az MI _k√∂vetkezetesen_ viselkedjen a meghat√°rozott √©rt√©kekkel √∂sszhangban, minimaliz√°lva a potenci√°lis k√°rokat vagy nem sz√°nd√©kos k√∂vetkezm√©nyeket.
* [**Adatv√©delem √©s biztons√°g**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - az adatok eredet√©nek meg√©rt√©s√©r≈ël √©s a felhaszn√°l√≥k sz√°m√°ra _adatv√©delem √©s kapcsol√≥d√≥ v√©delem_ biztos√≠t√°s√°r√≥l sz√≥l.
* [**Befogad√°s**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - az MI-megold√°sok sz√°nd√©kos tervez√©s√©r≈ël sz√≥l, hogy azok _sz√©les k√∂r≈± emberi ig√©nyekhez_ √©s k√©pess√©gekhez alkalmazkodjanak.

> üö® Gondolkodj el azon, hogy mi lehetne a te adatetikai k√ºldet√©snyilatkozatod. Fedezd fel m√°s szervezetek etikus MI-keretrendszereit - itt van n√©h√°ny p√©lda: [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles), √©s [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Milyen k√∂z√∂s √©rt√©keket tal√°lsz benn√ºk? Hogyan kapcsol√≥dnak ezek az elvek az √°ltaluk m≈±k√∂dtetett MI-term√©kekhez vagy ipar√°gakhoz?

### 2. Etikai kih√≠v√°sok

Miut√°n meghat√°roztuk az etikai elveket, a k√∂vetkez≈ë l√©p√©s az adat- √©s MI-m≈±veleteink √©rt√©kel√©se annak √©rdek√©ben, hogy azok √∂sszhangban √°llnak-e ezekkel a k√∂z√∂s √©rt√©kekkel. Gondolj a cselekedeteidre k√©t kateg√≥ri√°ban: _adatgy≈±jt√©s_ √©s _algoritmus tervez√©s_.

Az adatok gy≈±jt√©se sor√°n a m≈±veletek val√≥sz√≠n≈±leg **szem√©lyes adatokat** vagy szem√©lyesen azonos√≠that√≥ inform√°ci√≥kat (PII) √©rintenek, amelyek azonos√≠that√≥ √©l≈ë szem√©lyekre vonatkoznak. Ez mag√°ban foglalja a [k√ºl√∂nf√©le nem szem√©lyes adatokat](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en), amelyek _egy√ºttesen_ azonos√≠tanak egy szem√©lyt. Az etikai kih√≠v√°sok kapcsol√≥dhatnak az _adatv√©delemhez_, _adatbirtokl√°shoz_ √©s kapcsol√≥d√≥ t√©m√°khoz, mint p√©ld√°ul a _t√°j√©kozott beleegyez√©s_ √©s a _felhaszn√°l√≥i szellemi tulajdonjogok_.

Az algoritmus tervez√©se sor√°n a m≈±veletek magukban foglalj√°k a **adatk√©szletek** gy≈±jt√©s√©t √©s kur√°l√°s√°t, majd ezek felhaszn√°l√°s√°t **adatmodellek** betan√≠t√°s√°ra √©s telep√≠t√©s√©re, amelyek val√≥s k√∂rnyezetben j√≥solnak eredm√©nyeket vagy automatiz√°lnak d√∂nt√©seket. Az etikai kih√≠v√°sok felmer√ºlhetnek az _adatk√©szlet torz√≠t√°s√°b√≥l_, _adatmin≈ës√©gi_ probl√©m√°kb√≥l, _m√©lt√°nytalans√°gb√≥l_ √©s _f√©lrevezet√©sb≈ël_ az algoritmusokban - bele√©rtve n√©h√°ny rendszerszint≈± probl√©m√°t is.

Mindk√©t esetben az etikai kih√≠v√°sok olyan ter√ºleteket emelnek ki, ahol cselekedeteink konfliktusba ker√ºlhetnek k√∂z√∂s √©rt√©keinkkel. Az ilyen agg√°lyok √©szlel√©s√©hez, enyh√≠t√©s√©hez, minimaliz√°l√°s√°hoz vagy megsz√ºntet√©s√©hez erk√∂lcsi "igen/nem" k√©rd√©seket kell feltenn√ºnk a cselekedeteinkkel kapcsolatban, majd sz√ºks√©g eset√©n korrekci√≥s int√©zked√©seket kell tenn√ºnk. N√©zz√ºnk meg n√©h√°ny etikai kih√≠v√°st √©s az √°ltaluk felvetett erk√∂lcsi k√©rd√©seket:

#### 2.1 Adatbirtokl√°s

Az adatok gy≈±jt√©se gyakran szem√©lyes adatokat √©rint, amelyek az adat alanyait azonos√≠thatj√°k. Az [adatbirtokl√°s](https://permission.io/blog/data-ownership) az adatok l√©trehoz√°s√°val, feldolgoz√°s√°val √©s terjeszt√©s√©vel kapcsolatos _ellen≈ërz√©sr≈ël_ √©s [_felhaszn√°l√≥i jogokr√≥l_](https://permission.io/blog/data-ownership) sz√≥l.

Az erk√∂lcsi k√©rd√©sek, amelyeket fel kell tenn√ºnk:
 * Ki birtokolja az adatokat? (felhaszn√°l√≥ vagy szervezet)
 * Milyen jogai vannak az adat alanyainak? (pl. hozz√°f√©r√©s, t√∂rl√©s, hordozhat√≥s√°g)
 * Milyen jogai vannak a szervezeteknek? (pl. rosszindulat√∫ felhaszn√°l√≥i v√©lem√©nyek helyesb√≠t√©se)

#### 2.2 T√°j√©kozott beleegyez√©s

A [t√°j√©kozott beleegyez√©s](https://legaldictionary.net/informed-consent/) azt jelenti, hogy a felhaszn√°l√≥k egy cselekv√©shez (p√©ld√°ul adatgy≈±jt√©shez) _teljes k√∂r≈± meg√©rt√©ssel_ j√°rulnak hozz√°, bele√©rtve a c√©lokat, a lehets√©ges kock√°zatokat √©s az alternat√≠v√°kat.

Itt feltett k√©rd√©sek:
 * A felhaszn√°l√≥ (adat alanya) enged√©lyt adott az adatok r√∂gz√≠t√©s√©re √©s felhaszn√°l√°s√°ra?
 * A felhaszn√°l√≥ meg√©rtette, hogy mi c√©lb√≥l gy≈±jt√∂tt√©k az adatokat?
 * A felhaszn√°l√≥ meg√©rtette a r√©szv√©tel√©b≈ël ered≈ë lehets√©ges kock√°zatokat?

#### 2.3 Szellemi tulajdon

A [szellemi tulajdon](https://en.wikipedia.org/wiki/Intellectual_property) az emberi kezdem√©nyez√©sb≈ël sz√°rmaz√≥ immateri√°lis alkot√°sokra utal, amelyek _gazdas√°gi √©rt√©kkel_ b√≠rhatnak egy√©nek vagy v√°llalkoz√°sok sz√°m√°ra.

Itt feltett k√©rd√©sek:
 * Az √∂sszegy≈±jt√∂tt adatok gazdas√°gi √©rt√©kkel b√≠rnak-e egy felhaszn√°l√≥ vagy v√°llalkoz√°s sz√°m√°ra?
 * Van-e a **felhaszn√°l√≥nak** szellemi tulajdona itt?
 * Van-e a **szervezetnek** szellemi tulajdona itt?
 * Ha ezek a jogok l√©teznek, hogyan v√©dj√ºk ≈ëket?

#### 2.4 Adatv√©delem

Az [adatv√©delem](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) vagy inform√°ci√≥s mag√°n√©let a felhaszn√°l√≥i mag√°n√©let meg≈ërz√©s√©re √©s a felhaszn√°l√≥i identit√°s v√©delm√©re vonatkozik a szem√©lyesen azonos√≠that√≥ inform√°ci√≥k tekintet√©ben.

Itt feltett k√©rd√©sek:
 * A felhaszn√°l√≥k (szem√©lyes) adatai v√©dettek-e a hackel√©sekkel √©s sziv√°rg√°sokkal szemben?
 * A felhaszn√°l√≥k adatai csak jogosult felhaszn√°l√≥k √©s kontextusok sz√°m√°ra √©rhet≈ëk el?
 * A felhaszn√°l√≥k anonimit√°sa megmarad-e, amikor az adatokat megosztj√°k vagy terjesztik?
 * Egy felhaszn√°l√≥
[Algorithmusok m√©lt√°nyoss√°ga](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) azt vizsg√°lja, hogy az algoritmus tervez√©se szisztematikusan diszkrimin√°lja-e az adatk√∂z√∂ss√©gek bizonyos alcsoportjait, ami [potenci√°lis k√°rokat](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) okozhat az _er≈ëforr√°sok eloszt√°s√°ban_ (amikor az er≈ëforr√°sokat megtagadj√°k vagy visszatartj√°k az adott csoportt√≥l) √©s a _szolg√°ltat√°s min≈ës√©g√©ben_ (amikor az AI nem olyan pontos bizonyos alcsoportok eset√©ben, mint m√°sokn√°l).

K√©rd√©sek, amelyeket √©rdemes megvizsg√°lni:
 * √ârt√©kelt√ºk-e a modell pontoss√°g√°t k√ºl√∂nb√∂z≈ë alcsoportok √©s k√∂r√ºlm√©nyek k√∂z√∂tt?
 * Vizsg√°ltuk-e a rendszert potenci√°lis k√°rok (pl. sztereot√≠pi√°k) szempontj√°b√≥l?
 * Tudjuk-e m√≥dos√≠tani az adatokat vagy √∫jratan√≠tani a modelleket az azonos√≠tott k√°rok enyh√≠t√©se √©rdek√©ben?

Fedezz fel olyan forr√°sokat, mint az [AI m√©lt√°nyoss√°gi ellen≈ërz≈ëlist√°k](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA), hogy t√∂bbet megtudj.

#### 2.9 F√©lrevezet√©s

[Adataz f√©lrevezet√©se](https://www.sciencedirect.com/topics/computer-science/misrepresentation) arra vonatkozik, hogy vajon ≈ëszint√©n jelentett adatokb√≥l sz√°rmaz√≥ betekint√©seket megt√©veszt≈ë m√≥don kommunik√°lunk-e, hogy t√°mogassunk egy k√≠v√°nt narrat√≠v√°t.

K√©rd√©sek, amelyeket √©rdemes megvizsg√°lni:
 * Jelent√ºnk-e hi√°nyos vagy pontatlan adatokat?
 * √ögy vizualiz√°ljuk-e az adatokat, hogy f√©lrevezet≈ë k√∂vetkeztet√©seket vonjanak le bel≈ël√ºk?
 * Haszn√°lunk-e szelekt√≠v statisztikai technik√°kat az eredm√©nyek manipul√°l√°s√°ra?
 * Vannak-e alternat√≠v magyar√°zatok, amelyek m√°s k√∂vetkeztet√©st k√≠n√°lhatnak?

#### 2.10 Szabad v√°laszt√°s
A [szabad v√°laszt√°s ill√∫zi√≥ja](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) akkor fordul el≈ë, amikor a rendszer "v√°laszt√°si architekt√∫r√°i" d√∂nt√©shoz√≥ algoritmusokat haszn√°lnak arra, hogy az embereket egy prefer√°lt eredm√©ny fel√© terelj√©k, mik√∂zben √∫gy t≈±nik, hogy lehet≈ës√©geket √©s kontrollt adnak nekik. Ezek a [s√∂t√©t mint√°k](https://www.darkpatterns.org/) t√°rsadalmi √©s gazdas√°gi k√°rokat okozhatnak a felhaszn√°l√≥knak. Mivel a felhaszn√°l√≥i d√∂nt√©sek befoly√°solj√°k a viselked√©si profilokat, ezek a cselekv√©sek potenci√°lisan meghat√°rozhatj√°k a j√∂v≈ëbeli v√°laszt√°sokat, amelyek feler≈ës√≠thetik vagy kiterjeszthetik a k√°rok hat√°s√°t.

K√©rd√©sek, amelyeket √©rdemes megvizsg√°lni:
 * √ârtette-e a felhaszn√°l√≥ annak a v√°laszt√°snak a k√∂vetkezm√©nyeit?
 * Tudott-e a felhaszn√°l√≥ az (alternat√≠v) v√°laszt√°si lehet≈ës√©gekr≈ël √©s azok el≈ënyeir≈ël √©s h√°tr√°nyair√≥l?
 * Visszaford√≠thatja-e a felhaszn√°l√≥ egy automatiz√°lt vagy befoly√°solt d√∂nt√©st k√©s≈ëbb?

### 3. Esettanulm√°nyok

Ahhoz, hogy ezeket az etikai kih√≠v√°sokat val√≥s kontextusba helyezz√ºk, √©rdemes olyan esettanulm√°nyokat megvizsg√°lni, amelyek kiemelik az egy√©nekre √©s a t√°rsadalomra gyakorolt potenci√°lis k√°rokat √©s k√∂vetkezm√©nyeket, amikor az ilyen etikai v√©ts√©geket figyelmen k√≠v√ºl hagyj√°k.

√çme n√©h√°ny p√©lda:

| Etikai kih√≠v√°s | Esettanulm√°ny  | 
|--- |--- |
| **T√°j√©kozott beleegyez√©s** | 1972 - [Tuskegee szifilisz tanulm√°ny](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Az afrikai-amerikai f√©rfiak, akik r√©szt vettek a tanulm√°nyban, ingyenes orvosi ell√°t√°st √≠g√©rtek, _de megt√©vesztett√©k_ ≈ëket a kutat√≥k, akik nem t√°j√©koztatt√°k ≈ëket a diagn√≥zisukr√≥l vagy a kezel√©s el√©rhet≈ës√©g√©r≈ël. Sok alany meghalt, √©s partnereik vagy gyermekeik is √©rintettek voltak; a tanulm√°ny 40 √©vig tartott. | 
| **Adatv√©delem** |  2007 - A [Netflix adatd√≠j](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) kutat√≥knak _10M anonimiz√°lt film√©rt√©kel√©st 50K √ºgyf√©lt≈ël_ biztos√≠tott, hogy jav√≠ts√°k az aj√°nl√°si algoritmusokat. Azonban a kutat√≥k k√©pesek voltak az anonimiz√°lt adatokat szem√©lyazonos√≠t√≥ adatokkal √∂sszekapcsolni _k√ºls≈ë adatb√°zisokban_ (pl. IMDb kommentek), hat√©konyan "deanonimiz√°lva" n√©h√°ny Netflix el≈ëfizet≈ët.|
| **Gy≈±jt√©si torz√≠t√°s**  | 2013 - Boston v√°rosa [kifejlesztette a Street Bump](https://www.boston.gov/transportation/street-bump) alkalmaz√°st, amely lehet≈ëv√© tette a polg√°rok sz√°m√°ra, hogy k√°ty√∫kat jelentsenek, jobb √∫th√°l√≥zati adatokat biztos√≠tva a v√°rosnak a probl√©m√°k megtal√°l√°s√°hoz √©s jav√≠t√°s√°hoz. Azonban [az alacsonyabb j√∂vedelm≈± csoportoknak kevesebb hozz√°f√©r√©s√ºk volt aut√≥khoz √©s telefonokhoz](https://hbr.org/2013/04/the-hidden-biases-in-big-data), √≠gy az ≈ë √∫th√°l√≥zati probl√©m√°ik l√°thatatlanok maradtak az alkalmaz√°sban. A fejleszt≈ëk akad√©mikusokkal dolgoztak egy√ºtt, hogy _m√©lt√°nyos hozz√°f√©r√©st √©s digit√°lis szakad√©kokat_ kezeljenek a m√©lt√°nyoss√°g √©rdek√©ben. |
| **Algoritmusok m√©lt√°nyoss√°ga**  | 2018 - Az MIT [Gender Shades Study](http://gendershades.org/overview.html) √©rt√©kelte a nemek oszt√°lyoz√°s√°ra szolg√°l√≥ AI term√©kek pontoss√°g√°t, felt√°rva a pontoss√°gi hi√°nyoss√°gokat a n≈ëk √©s sz√≠nes b≈ër≈±ek eset√©ben. Egy [2019-es Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) l√°tsz√≥lag kevesebb hitelt k√≠n√°lt a n≈ëknek, mint a f√©rfiaknak. Mindkett≈ë az algoritmikus torz√≠t√°s probl√©m√°it illusztr√°lta, amelyek t√°rsadalmi-gazdas√°gi k√°rokat okoztak.|
| **Adatok f√©lrevezet√©se** | 2020 - A [Georgia Eg√©szs√©g√ºgyi Miniszt√©rium COVID-19 grafikonokat](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) tett k√∂zz√©, amelyek l√°tsz√≥lag f√©lrevezett√©k a polg√°rokat az igazolt esetek trendjeir≈ël, nem kronol√≥giai sorrendben az x-tengelyen. Ez a vizualiz√°ci√≥s tr√ºkk√∂k √°ltali f√©lrevezet√©st illusztr√°lja. |
| **Szabad v√°laszt√°s ill√∫zi√≥ja** | 2020 - A tanul√°si alkalmaz√°s [ABCmouse 10M doll√°rt fizetett az FTC panasz rendez√©s√©re](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/), ahol a sz√ºl≈ëk nem tudt√°k lemondani az el≈ëfizet√©seket, amelyekbe belecs√∫sztak. Ez a v√°laszt√°si architekt√∫r√°k s√∂t√©t mint√°it illusztr√°lja, ahol a felhaszn√°l√≥kat potenci√°lisan k√°ros d√∂nt√©sek fel√© terelt√©k. |
| **Adatv√©delem √©s felhaszn√°l√≥i jogok** | 2021 - A Facebook [adatv√©delmi incidens](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) 530M felhaszn√°l√≥ adatait tette ki, ami 5B doll√°ros egyezs√©get eredm√©nyezett az FTC-vel. Azonban megtagadta a felhaszn√°l√≥k √©rtes√≠t√©s√©t az incidensr≈ël, megs√©rtve a felhaszn√°l√≥i jogokat az adat√°tl√°that√≥s√°g √©s hozz√°f√©r√©s ter√©n. |

Szeretn√©l tov√°bbi esettanulm√°nyokat felfedezni? N√©zd meg ezeket a forr√°sokat:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etikai dilemm√°k k√ºl√∂nb√∂z≈ë ipar√°gakban. 
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - m√©rf√∂ldk≈ënek sz√°m√≠t√≥ esettanulm√°nyok.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - deon ellen≈ërz≈ëlista p√©ld√°kkal.

> üö® Gondolj azokra az esettanulm√°nyokra, amelyeket l√°tt√°l - tapasztalt√°l vagy √©rintett-e hasonl√≥ etikai kih√≠v√°st az √©letedben? Tudsz legal√°bb egy m√°sik esettanulm√°nyt, amely illusztr√°lja az ebben a szakaszban t√°rgyalt etikai kih√≠v√°sok egyik√©t?

## Alkalmazott etika

Besz√©lt√ºnk az etikai fogalmakr√≥l, kih√≠v√°sokr√≥l √©s esettanulm√°nyokr√≥l val√≥s kontextusban. De hogyan kezdhetj√ºk el _alkalmazni_ az etikai elveket √©s gyakorlatokat a projektjeinkben? √âs hogyan _operacionaliz√°lhatjuk_ ezeket a gyakorlatokat a jobb ir√°ny√≠t√°s √©rdek√©ben? N√©zz√ºnk meg n√©h√°ny val√≥s megold√°st:

### 1. Szakmai k√≥dexek

A szakmai k√≥dexek egy lehet≈ës√©get k√≠n√°lnak a szervezetek sz√°m√°ra, hogy "√∂szt√∂n√∂zz√©k" tagjaikat az etikai elveik √©s k√ºldet√©s√ºk t√°mogat√°s√°ra. A k√≥dexek _erk√∂lcsi ir√°nymutat√°sok_ a szakmai viselked√©shez, seg√≠tve az alkalmazottakat vagy tagokat olyan d√∂nt√©sek meghozatal√°ban, amelyek √∂sszhangban vannak a szervezet elveivel. Csak annyira hat√©konyak, amennyire a tagok √∂nk√©ntes megfelel√©se; azonban sok szervezet tov√°bbi jutalmakat √©s b√ºntet√©seket k√≠n√°l, hogy motiv√°lja a tagokat a megfelel√©sre.

P√©ld√°k:
 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Etikai K√≥dex
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Magatart√°si K√≥dex (2013-ban l√©trehozva)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (1993 √≥ta)

> üö® Tagja vagy valamilyen szakmai m√©rn√∂ki vagy adatkutat√°si szervezetnek? N√©zd meg a weboldalukat, hogy meghat√°roznak-e szakmai etikai k√≥dexet. Mit mond ez az etikai elveikr≈ël? Hogyan "√∂szt√∂nzik" a tagokat a k√≥dex k√∂vet√©s√©re?

### 2. Etikai ellen≈ërz≈ëlist√°k

M√≠g a szakmai k√≥dexek meghat√°rozz√°k a szakemberek _etikai viselked√©s√©t_, [ismert korl√°tokkal](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) rendelkeznek a v√©grehajt√°sban, k√ºl√∂n√∂sen nagyszab√°s√∫ projektek eset√©ben. Ehelyett sok adatkutat√°si szak√©rt≈ë [ellen≈ërz≈ëlist√°kat javasol](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), amelyek **√∂sszekapcsolj√°k az elveket a gyakorlatokkal** determinisztikusabb √©s cselekv≈ëk√©pesebb m√≥don.

Az ellen≈ërz≈ëlist√°k a k√©rd√©seket "igen/nem" feladatokk√° alak√≠tj√°k, amelyek operacionaliz√°lhat√≥k, lehet≈ëv√© t√©ve, hogy nyomon k√∂vess√©k ≈ëket a szok√°sos term√©kkiad√°si munkafolyamatok r√©szek√©nt.

P√©ld√°k:
 * [Deon](https://deon.drivendata.org/) - √°ltal√°nos c√©l√∫ adatetikai ellen≈ërz≈ëlista, amelyet [ipar√°gi aj√°nl√°sok](https://deon.drivendata.org/#checklist-citations) alapj√°n hoztak l√©tre, parancssori eszk√∂zzel a k√∂nny≈± integr√°ci√≥ √©rdek√©ben.
 * [Adatv√©delmi audit ellen≈ërz≈ëlista](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - √°ltal√°nos ir√°nymutat√°st ny√∫jt az inform√°ci√≥kezel√©si gyakorlatokhoz jogi √©s t√°rsadalmi kitetts√©g szempontj√°b√≥l.
 * [AI m√©lt√°nyoss√°gi ellen≈ërz≈ëlista](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - AI szakemberek √°ltal l√©trehozva, hogy t√°mogass√°k a m√©lt√°nyoss√°gi ellen≈ërz√©sek bevezet√©s√©t √©s integr√°ci√≥j√°t az AI fejleszt√©si ciklusokba.
 * [22 k√©rd√©s az adatok √©s AI etik√°j√°r√≥l](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - nyitottabb keretrendszer, amelyet az etikai k√©rd√©sek kezdeti felt√°r√°s√°ra struktur√°ltak a tervez√©s, megval√≥s√≠t√°s √©s szervezeti kontextusokban.

### 3. Etikai szab√°lyoz√°sok

Az etika k√∂z√∂s √©rt√©kek meghat√°roz√°s√°r√≥l √©s a helyes cselekv√©sr≈ël sz√≥l _√∂nk√©ntesen_. **Megfelel√©s** arr√≥l sz√≥l, hogy _k√∂vetj√ºk a t√∂rv√©nyt_, ha √©s ahol meghat√°rozt√°k. **Ir√°ny√≠t√°s** sz√©lesebb √©rtelemben mag√°ban foglalja az √∂sszes m√≥dot, ahogyan a szervezetek m≈±k√∂dnek az etikai elvek √©rv√©nyes√≠t√©se √©s a meghat√°rozott t√∂rv√©nyek betart√°sa √©rdek√©ben.

Ma az ir√°ny√≠t√°s k√©t form√°t √∂lt a szervezeteken bel√ºl. El≈ësz√∂r is, az **etikus AI** elvek meghat√°roz√°s√°r√≥l √©s a gyakorlatok l√©trehoz√°s√°r√≥l sz√≥l, hogy operacionaliz√°lj√°k az elfogad√°st az √∂sszes AI-val kapcsolatos projektben a szervezeten bel√ºl. M√°sodszor, arr√≥l sz√≥l, hogy megfeleljenek az √∂sszes korm√°ny √°ltal el≈ë√≠rt **adatv√©delmi szab√°lyoz√°snak** azokban a r√©gi√≥kban, ahol m≈±k√∂dnek.

Adatv√©delmi √©s adatv√©delmi szab√°lyoz√°sok p√©ld√°i:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - szab√°lyozza a _sz√∂vets√©gi korm√°ny_ szem√©lyes inform√°ci√≥k gy≈±jt√©s√©t, haszn√°lat√°t √©s k√∂zz√©t√©tel√©t.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - v√©di a szem√©lyes eg√©szs√©g√ºgyi adatokat.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - v√©di a 13 √©v alatti gyermekek adatv√©delm√©t.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - felhaszn√°l√≥i jogokat, adatv√©delmet √©s adatbiztons√°got biztos√≠t.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) t√∂bb _jogot_ biztos√≠t a fogyaszt√≥knak a (szem√©lyes) adataik felett.
 * `2021`, K√≠na [Szem√©lyes Inform√°ci√≥k V√©delmi T√∂rv√©nye](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) √©ppen elfogadva, l√©trehozva az egyik leger≈ësebb online adatv√©delmi szab√°lyoz√°st vil√°gszerte.

> üö® Az Eur√≥pai Uni√≥ √°ltal meghat√°rozott GDPR (√Åltal√°nos Adatv√©delmi Rendelet) ma az egyik legbefoly√°sosabb adatv√©delmi szab√°lyoz√°s. Tudtad, hogy [8 felhaszn√°l√≥i jogot](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) is meghat√°roz a digit√°lis adatv√©delem √©s szem√©lyes adatok v√©delme √©rdek
* [A felel≈ës mesters√©ges intelligencia alapelvei](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - ingyenes tanul√°si √∫tvonal a Microsoft Learn-t≈ël.
* [Etika √©s adattudom√°ny](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EBook (M. Loukides, H. Mason √©s m√°sok)
* [Adattudom√°nyi etika](https://www.coursera.org/learn/data-science-ethics#syllabus) - online kurzus a Michigani Egyetemt≈ël.
* [Etika kibontva](https://ethicsunwrapped.utexas.edu/case-studies) - esettanulm√°nyok a Texasi Egyetemt≈ël.

# Feladat 

[√çrj egy esettanulm√°nyt az adatetik√°r√≥l](assignment.md)

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az AI ford√≠t√°si szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.